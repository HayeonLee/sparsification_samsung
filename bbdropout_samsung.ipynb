{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bbdropout_samsung",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HayeonLee/sparsification_samsung/blob/master/bbdropout_samsung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD6bQj0iVZM9",
        "colab_type": "text"
      },
      "source": [
        "# Network Sparsification Example : Beta-Bernoulli Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSc0p6Y6VvoL",
        "colab_type": "text"
      },
      "source": [
        "[Adaptive Network Sparsification with Dependent Variational Beta-Bernoulli Dropout](https://arxiv.org/abs/1805.10896)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP0DgMlDV64u",
        "colab_type": "text"
      },
      "source": [
        "## Import Tensorflow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNpLz5neUrqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "#기존에 설치된 다른 버전의 tensorflow를 제거합니다.\n",
        "!pip uninstall tensorboard -y\n",
        "!pip uninstall tensorflow-gpu -y\n",
        "!pip uninstall tensorflow -y\n",
        "#tensorflow gpu 버전을 설치합니다\n",
        "!pip install tensorflow-gpu==1.14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68oyuhXNWEQ6",
        "colab_type": "code",
        "outputId": "9201ec06-744c-4d08-be21-0600b956f3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf # tensorflow를 import해줍니다\n",
        "tf.__version__ # 내가 사용할 tensorflow의 버전을 나타냅니다"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.14.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkYfIMpyYdPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pretrain된 lenet의 체크포인트 파일을 가져옵니다.\n",
        "!mkdir -p results/\n",
        "!wget -O lenet_dense_pretrained.zip https://github.com/HayeonLee/sparsification_samsung/blob/master/lenet_dense_pretrained.zip?raw=true\n",
        "!unzip lenet_dense_pretrained.zip -d results/\n",
        "!rm lenet_dense_pretrained.zip\n",
        "!ls\n",
        "!ls results/pretrained/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR4m7OXGAt8i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 필요한 라이브러리를 임포트합니다.\n",
        "from __future__ import print_function\n",
        "import time\n",
        "import os\n",
        "from pylab import *\n",
        "import numpy as np\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.contrib.distributions import RelaxedBernoulli\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ0R62L8WvSu",
        "colab_type": "text"
      },
      "source": [
        "## Define the functions and utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFCAzQYqfrzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph() # 기존의 그려진 텐서플로우 그래프를 제거합니다.\n",
        "# layers.py\n",
        "# 자주 쓰는 텐서플로우 함수의 약어를 지정합니다.\n",
        "logit = lambda x: tf.log(x + 1e-20) - tf.log(1-x + 1e-20)\n",
        "softplus = tf.nn.softplus\n",
        "relu = tf.nn.relu\n",
        "\n",
        "dense = tf.layers.dense\n",
        "flatten = tf.contrib.layers.flatten\n",
        "\n",
        "def conv(x, filters, kernel_size=3, strides=1, **kwargs):\n",
        "    return tf.layers.conv2d(x, filters, kernel_size, strides,\n",
        "            data_format='channels_first', **kwargs)\n",
        "\n",
        "def pool(x, **kwargs):\n",
        "    return tf.layers.max_pooling2d(x, 2, 2,\n",
        "            data_format='channels_first', **kwargs)\n",
        "\n",
        "def global_avg_pool(x):\n",
        "    return tf.reduce_mean(x, axis=[2, 3])\n",
        "\n",
        "layer_norm = tf.contrib.layers.layer_norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJrRN4ujgQh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# utils/train.py\n",
        "# 필요한 함수를 정의합니다.\n",
        "def cross_entropy(logits, labels):\n",
        "    return tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=labels)\n",
        "\n",
        "def weight_decay(decay, var_list=None):\n",
        "    var_list = tf.trainable_variables() if var_list is None else var_list\n",
        "    return decay*tf.add_n([tf.nn.l2_loss(var) for var in var_list])\n",
        "\n",
        "def accuracy(logits, labels):\n",
        "    correct = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
        "    return tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "  \n",
        "def digamma_approx(x):\n",
        "# @MISC {1446110,\n",
        "# TITLE = {Approximating the Digamma function},\n",
        "# AUTHOR = {njuffa (https://math.stackexchange.com/users/114200/njuffa)},\n",
        "# HOWPUBLISHED = {Mathematics Stack Exchange},\n",
        "# NOTE = {URL:https://math.stackexchange.com/q/1446110 (version: 2015-09-22)},\n",
        "# EPRINT = {https://math.stackexchange.com/q/1446110},\n",
        "# URL = {https://math.stackexchange.com/q/1446110}}\n",
        "    def digamma_over_one(x):\n",
        "        return tf.log(x + 0.4849142940227510) \\\n",
        "                - 1/(1.0271785180163817*x)\n",
        "    return digamma_over_one(x+1) - 1./x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x9RShCp_DDOz",
        "colab": {}
      },
      "source": [
        "# utils/accmulator.py\n",
        "# log를 출력하기 위한 함수를 선언합니다.\n",
        "class Accumulator():\n",
        "    def __init__(self, *args):\n",
        "        self.args = args\n",
        "        self.argdict = {}\n",
        "        for i, arg in enumerate(args):\n",
        "            self.argdict[arg] = i\n",
        "        self.sums = [0]*len(args)\n",
        "        self.cnt = 0\n",
        "\n",
        "    def accum(self, val):\n",
        "        val = [val] if type(val) is not list else val\n",
        "        val = [v for v in val if v is not None]\n",
        "        assert(len(val) == len(self.args))\n",
        "        for i in range(len(val)):\n",
        "            self.sums[i] += val[i]\n",
        "        self.cnt += 1\n",
        "\n",
        "    def clear(self):\n",
        "        self.sums = [0]*len(self.args)\n",
        "        self.cnt = 0\n",
        "\n",
        "    def get(self, arg, avg=True):\n",
        "        i = self.argdict.get(arg, -1)\n",
        "        assert(i is not -1)\n",
        "        return (self.sums[i]/self.cnt if avg else self.sums[i])\n",
        "\n",
        "    def print_(self, header=None, epoch=None, it=None, time=None,\n",
        "            logfile=None, do_not_print=[], as_int=[],\n",
        "            avg=True):\n",
        "        line = '' if header is None else header + ': '\n",
        "        if epoch is not None:\n",
        "            line += ('epoch %d, ' % epoch)\n",
        "        if it is not None:\n",
        "            line += ('iter %d, ' % it)\n",
        "        if time is not None:\n",
        "            line += ('(%.3f secs), ' % time)\n",
        "\n",
        "        args = [arg for arg in self.args if arg not in do_not_print]\n",
        "\n",
        "        for arg in args[:-1]:\n",
        "            val = self.sums[self.argdict[arg]]\n",
        "            if avg:\n",
        "                val /= self.cnt\n",
        "            if arg in as_int:\n",
        "                line += ('%s %d, ' % (arg, int(val)))\n",
        "            else:\n",
        "                line += ('%s %f, ' % (arg, val))\n",
        "        val = self.sums[self.argdict[args[-1]]]\n",
        "        if avg:\n",
        "            val /= self.cnt\n",
        "        if arg in as_int:\n",
        "            line += ('%s %d, ' % (arg, int(val)))\n",
        "        else:\n",
        "            line += ('%s %f' % (args[-1], val))\n",
        "        print(line)\n",
        "\n",
        "        if logfile is not None:\n",
        "            logfile.write(line + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF1WUmZRIdss",
        "colab_type": "text"
      },
      "source": [
        "## Prepare the dataset: MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q21ZNy8bhTpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MNIST_PATH = './mnist'\n",
        "\n",
        "def mnist_input(batch_size):\n",
        "    mnist = input_data.read_data_sets(MNIST_PATH, one_hot=True, validation_size=0)\n",
        "    n_train_batches = mnist.train.num_examples/batch_size\n",
        "    n_test_batches = mnist.test.num_examples/batch_size\n",
        "    return mnist, n_train_batches, n_test_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3lKC6JjHRKM",
        "colab_type": "text"
      },
      "source": [
        "##Create models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg7YnEexflxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lenet_dense(x, y, training, name='lenet', reuse=None,\n",
        "        dropout=None, **dropout_kwargs):\n",
        "    dropout_ = lambda x, subname: x if dropout is None else \\\n",
        "            dropout(x, training, name=name+subname, reuse=reuse,\n",
        "                    **dropout_kwargs)\n",
        "    x = dense(dropout_(x, '/dropout1'), 500, activation=relu,\n",
        "            name=name+'/dense1', reuse=reuse)\n",
        "    x = dense(dropout_(x, '/dropout2'), 300, activation=relu,\n",
        "            name=name+'/dense2', reuse=reuse)\n",
        "    x = dense(dropout_(x, '/dropout3'), 10, name=name+'/dense3', reuse=reuse)\n",
        "\n",
        "    net = {}\n",
        "    all_vars = tf.get_collection('variables', scope=name)\n",
        "    net['qpi_vars'] = [v for v in all_vars if 'qpi_vars' in v.name]\n",
        "    net['pzx_vars'] = [v for v in all_vars if 'pzx_vars' in v.name]\n",
        "    net['weights'] = [v for v in all_vars \\\n",
        "            if 'qpi_vars' not in v.name and 'pzx_vars' not in v.name]\n",
        "\n",
        "    net['cent'] = cross_entropy(x, y)\n",
        "    net['wd'] = weight_decay(1e-4, var_list=net['weights'])\n",
        "    net['acc'] = accuracy(x, y)\n",
        "\n",
        "    prefix = 'train_' if training else 'test_'\n",
        "    net['kl'] = tf.get_collection('kl')\n",
        "    net['pi'] = tf.get_collection(prefix+'pi')\n",
        "    net['n_active'] = tf.get_collection(prefix+'n_active')\n",
        "\n",
        "    return net\n",
        "\n",
        "# def lenet_conv(x, y, training, name='lenet', reuse=None,\n",
        "#         dropout=None, **dropout_kwargs):\n",
        "#     dropout_ = lambda x, subname: x if dropout is None else \\\n",
        "#             dropout(x, training, name=name+subname, reuse=reuse,\n",
        "#                     **dropout_kwargs)\n",
        "#     x = tf.reshape(x, [-1, 1, 28, 28])\n",
        "#     x = conv(x, 20, 5, name=name+'/conv1', reuse=reuse)\n",
        "#     x = relu(dropout_(x, '/dropout1'))\n",
        "#     x = pool(x, name=name+'/pool1')\n",
        "#     x = conv(x, 50, 5, name=name+'/conv2', reuse=reuse)\n",
        "#     x = relu(dropout_(x, '/dropout2'))\n",
        "#     x = pool(x, name=name+'/pool2')\n",
        "#     x = flatten(x)\n",
        "#     x = dense(dropout_(x, '/dropout3'), 500, activation=relu,\n",
        "#             name=name+'/dense1', reuse=reuse)\n",
        "#     x = dense(dropout_(x, '/dropout4'), 10, name=name+'/dense2', reuse=reuse)\n",
        "\n",
        "#     net = {}\n",
        "#     all_vars = tf.get_collection('variables', scope=name)\n",
        "#     net['qpi_vars'] = [v for v in all_vars if 'qpi_vars' in v.name]\n",
        "#     net['pzx_vars'] = [v for v in all_vars if 'pzx_vars' in v.name]\n",
        "#     net['weights'] = [v for v in all_vars \\\n",
        "#             if 'qpi_vars' not in v.name and 'pzx_vars' not in v.name]\n",
        "\n",
        "#     net['cent'] = cross_entropy(x, y)\n",
        "#     net['wd'] = weight_decay(1e-4, var_list=net['weights'])\n",
        "#     net['acc'] = accuracy(x, y)\n",
        "\n",
        "#     prefix = 'train_' if training else 'test_'\n",
        "#     net['kl'] = tf.get_collection('kl')\n",
        "#     net['pi'] = tf.get_collection(prefix+'pi')\n",
        "#     net['n_active'] = tf.get_collection(prefix+'n_active')\n",
        "\n",
        "#     return net\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA7g-bi7IP6w",
        "colab_type": "text"
      },
      "source": [
        "## Define the Beta-Bernoulli Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJjoi_-lga15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model/bbdropout.py\n",
        "\n",
        "lgamma = tf.lgamma\n",
        "Euler = 0.577215664901532\n",
        "\n",
        "def bbdropout(x, training,\n",
        "        alpha=1e-4, thres=1e-2, a_init=-1., tau=1e-1, center_init=1.0,\n",
        "        approx_digamma=True, scale_kl=None, dep=False,\n",
        "        unit_scale=True, collect=True,\n",
        "        name='bbdropout', reuse=None):\n",
        "\n",
        "    N = tf.shape(x)[0]\n",
        "    K = x.shape[1].value\n",
        "    is_conv = len(x.shape)==4\n",
        "    log = lambda x: tf.log(x + 1e-20)\n",
        "\n",
        "\n",
        "    with tf.variable_scope(name+'/qpi_vars', reuse=reuse):\n",
        "        with tf.device('/cpu:0'):\n",
        "            a = softplus(tf.get_variable('a_uc', shape=[K],\n",
        "                initializer=tf.constant_initializer(a_init)))\n",
        "            b = softplus(tf.get_variable('b_uc', shape=[K]))\n",
        "\n",
        "    _digamma = digamma_approx \n",
        "    kl = (a-alpha)/a * (-Euler - _digamma(b) - 1/b) \\\n",
        "            + log(a*b) - log(alpha) - (b-1)/b\n",
        "    pi = (1 - tf.random_uniform([K])**(1/b))**(1/a) if training else \\\n",
        "            b*tf.exp(lgamma(1+1/a) + lgamma(b) - lgamma(1+1/a+b))\n",
        "\n",
        "    def hard_sigmoid(x):\n",
        "        return tf.clip_by_value(x, thres, 1-thres)\n",
        "\n",
        "    if dep:\n",
        "        with tf.variable_scope(name+'/pzx_vars', reuse=reuse):\n",
        "            hid = global_avg_pool(x) if is_conv else x\n",
        "            hid = tf.stop_gradient(hid)\n",
        "            with tf.device('/cpu:0'):\n",
        "                hid = layer_norm(hid, scale=False, center=False)\n",
        "                scale = tf.get_variable('scale', shape=[1 if unit_scale else K],\n",
        "                        initializer=tf.ones_initializer())\n",
        "                center = tf.get_variable('center', shape=[K],\n",
        "                        initializer=tf.constant_initializer(center_init))\n",
        "            hid = scale*hid + center\n",
        "        if training:\n",
        "            pi = pi * hard_sigmoid(hid + tf.random_normal(shape=tf.shape(hid)))\n",
        "            z = RelaxedBernoulli(tau, logits=logit(pi)).sample()\n",
        "        else:\n",
        "            pi = pi * hard_sigmoid(hid)\n",
        "            z = tf.where(tf.greater(pi, thres), pi, tf.zeros_like(pi))\n",
        "        #n_active = tf.reduce_mean(\n",
        "        #        tf.reduce_sum(tf.cast(tf.greater(pi, thres), tf.int32), 1))\n",
        "        n_active = tf.reduce_sum(tf.cast(tf.greater(pi, thres), tf.int32), 1)\n",
        "        n_active = tf.reduce_sum(n_active)/N\n",
        "    else:\n",
        "        if training:\n",
        "            z = RelaxedBernoulli(tau, logits=logit(pi)).sample(N)\n",
        "        else:\n",
        "            pi_ = tf.where(tf.greater(pi, thres), pi, tf.zeros_like(pi))\n",
        "            z = tf.tile(tf.expand_dims(pi_, 0), [N, 1])\n",
        "        n_active = tf.reduce_sum(tf.cast(tf.greater(pi, thres), tf.int32))\n",
        "\n",
        "    if scale_kl is None:\n",
        "        kl = tf.reduce_sum(kl)\n",
        "    else:\n",
        "        kl = scale_kl * tf.reduce_mean(kl)\n",
        "\n",
        "    if collect:\n",
        "        if reuse is not True:\n",
        "            tf.add_to_collection('kl', kl)\n",
        "        prefix = 'train_' if training else 'test_'\n",
        "        tf.add_to_collection(prefix+'pi', pi)\n",
        "        tf.add_to_collection(prefix+'n_active', n_active)\n",
        "\n",
        "    z = tf.reshape(z, ([-1, K, 1, 1] if is_conv else [-1, K]))\n",
        "    return x*z\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InEG2TA3Iilj",
        "colab_type": "text"
      },
      "source": [
        "## Let's run the code!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz6djPqUWps9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretraindir = './results/pretrained' \n",
        "savedir = './results/bbdropout/sample_run' \n",
        "if not os.path.isdir(savedir):\n",
        "    os.makedirs(savedir)\n",
        "\n",
        "batch_size = 100\n",
        "n_epochs = 60\n",
        "save_freq = 20\n",
        "mnist, n_train_batches, n_test_batches = mnist_input(batch_size)\n",
        "x = tf.placeholder(tf.float32, [None, 784])\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "N = mnist.train.num_examples\n",
        "dropout = bbdropout\n",
        "net = lenet_dense(x, y, True, dropout=dropout)\n",
        "tnet = lenet_dense(x, y, False, reuse=True, dropout=dropout)\n",
        "\n",
        "\n",
        "def train():\n",
        "    loss = net['cent'] + tf.add_n(net['kl'])/float(N) + net['wd']\n",
        "    global_step = tf.train.get_or_create_global_step()\n",
        "    bdr = [int(n_train_batches*(n_epochs-1)*r) for r in [0.5, 0.75]]\n",
        "    vals = [1e-2, 1e-3, 1e-4]\n",
        "    lr = tf.train.piecewise_constant(tf.cast(global_step, tf.int32), bdr, vals)\n",
        "    train_op1 = tf.train.AdamOptimizer(lr).minimize(loss,\n",
        "            var_list=net['qpi_vars'], global_step=global_step)\n",
        "    train_op2 = tf.train.AdamOptimizer(0.1*lr).minimize(loss,\n",
        "            var_list=net['weights'])\n",
        "    train_op = tf.group(train_op1, train_op2)\n",
        "\n",
        "    pretrain_saver = tf.train.Saver(net['weights'])\n",
        "    saver = tf.train.Saver(net['weights']+net['qpi_vars'])\n",
        "    logfile = open(os.path.join(savedir, 'train.log'), 'w', 0)\n",
        "\n",
        "    sess = tf.Session()\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    pretrain_saver.restore(sess, os.path.join(pretraindir, 'model'))\n",
        "\n",
        "    train_logger = Accumulator('cent', 'acc')\n",
        "    train_to_run = [train_op, net['cent'], net['acc']]\n",
        "    test_logger = Accumulator('cent', 'acc')\n",
        "    test_to_run = [tnet['cent'], tnet['acc']]\n",
        "    for i in range(n_epochs):\n",
        "        line = 'Epoch %d start, learning rate %f' % (i+1, sess.run(lr))\n",
        "        print(line)\n",
        "        logfile.write(line + '\\n')\n",
        "        train_logger.clear()\n",
        "        start = time.time()\n",
        "        for j in range(n_train_batches):\n",
        "            bx, by = mnist.train.next_batch(batch_size)\n",
        "            train_logger.accum(sess.run(train_to_run, {x:bx, y:by}))\n",
        "        train_logger.print_(header='train', epoch=i+1,\n",
        "                time=time.time()-start, logfile=logfile)\n",
        "\n",
        "        test_logger.clear()\n",
        "        for j in range(n_test_batches):\n",
        "            bx, by = mnist.test.next_batch(batch_size)\n",
        "            test_logger.accum(sess.run(test_to_run, {x:bx, y:by}))\n",
        "        test_logger.print_(header='test', epoch=i+1,\n",
        "                time=time.time()-start, logfile=logfile)\n",
        "        line = 'kl: ' + str(sess.run(tnet['kl'])) + '\\n'\n",
        "        line += 'n_active: ' + str(sess.run(tnet['n_active'])) + '\\n'\n",
        "        print(line)\n",
        "        logfile.write(line+'\\n')\n",
        "\n",
        "        if (i+1)% save_freq == 0:\n",
        "            saver.save(sess, os.path.join(savedir, 'model'))\n",
        "\n",
        "    logfile.close()\n",
        "    saver.save(sess, os.path.join(savedir, 'model'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_0exUrqhel8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O72sZ36dIosC",
        "colab_type": "text"
      },
      "source": [
        "## Test Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYDT-eQ1kwQz",
        "colab_type": "code",
        "outputId": "74a686c8-5fda-453c-96fb-81f868193e04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "def test():\n",
        "    sess = tf.Session()\n",
        "    saver = tf.train.Saver(tnet['weights']+tnet['qpi_vars'])\n",
        "    saver.restore(sess, os.path.join(savedir, 'model'))\n",
        "    logger = Accumulator('cent', 'acc')\n",
        "    to_run = [tnet['cent'], tnet['acc']]\n",
        "    for j in range(n_test_batches):\n",
        "        bx, by = mnist.test.next_batch(batch_size)\n",
        "        logger.accum(sess.run(to_run, {x:bx, y:by}))\n",
        "    logger.print_(header='test')\n",
        "    line = 'kl: ' + str(sess.run(tnet['kl'])) + '\\n'\n",
        "    line += 'n_active: ' + str(sess.run(tnet['n_active'])) + '\\n'\n",
        "    print(line)\n",
        "    \n",
        "test()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test: cent 0.041483, acc 0.987500\n",
            "kl: [3655.5867, 2182.1533, 1475.2677]\n",
            "n_active: [369, 207, 150]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8y4uwf-IqiR",
        "colab_type": "text"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0xBULDNoNG_",
        "colab_type": "code",
        "outputId": "cafa9fbd-4d13-4f9d-a6e1-b5ac995acf05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "def visualize():\n",
        "    sess = tf.Session()\n",
        "    saver = tf.train.Saver(tnet['weights']+tnet['qpi_vars'])\n",
        "    saver.restore(sess, os.path.join(savedir, 'model'))\n",
        "\n",
        "    n_drop = len(tnet['n_active'])\n",
        "    fig = figure('pi', figsize=(8,6))\n",
        "    axarr = fig.subplots(n_drop)\n",
        "    for i in range(n_drop):\n",
        "        np_pi = sess.run(tnet['pi'][i]).reshape((1,-1))\n",
        "        im = axarr[i].imshow(np_pi, cmap='Blues', aspect='auto')\n",
        "        axarr[i].yaxis.set_visible(False)\n",
        "        axarr[i].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "        if i == n_drop-1:\n",
        "            axarr[i].set_xlabel('The Number of Neurons\\nLeNet [784, 500, 300]')\n",
        "        fig.colorbar(im, ax=axarr[i])\n",
        "    show()\n",
        "visualize()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGCCAYAAABaRzyuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntNYv+Cf0ZgQIvFcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}